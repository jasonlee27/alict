TASKS

  - [JL] using the seed dataset and its augmented dataset, re-train
    the models and see the performance on the other dataset.

  + [JL] split the test cases into seed and expanded test cases and
    sese the model prediction and compare them between the seed and
    expanded cases. if it is different, then the expanded element
    change the label.

  - [JL] get the testsuite in checklist githubpage and run the models
    with the testsuite and compare the performance between the
    checklist and our testsuite.

  - [JL] get the original test performance of the model tested.
  
  - [JL] expand the requirements defined to other testing linguistic
    capabilities.

  - [JL] evaluate the sugested words based on defined requirements and
    their tag of pos extracted from CFG difference

  
==========

  + [JL] extract word suggestion from language model (e.g. BERT)

  + [JL] given searched inputs that meets requirements

  + [JL] extract requirements from checklist sentiment analysis
    evaluation descriptions and search and transform input from
    database that meets the extracted requirements.
  
  + [JL] using expanded grammar of seed input grammar, how can we restrict 
    randomly generated sentences to meaningful natural language sentences?

  + [JL] make a new sentence generator. compared with the naive nltk generator,
    it needs to keep the seed input word and perturb it by replacing existing 
    words in the seed input with synonyms and adding new component in reference
    cfg.

  + [JL] search and transform input from dataset that meets the
    requirements extracted from 1st description (Short sentences with
    neutral adj and nouns)
    
  + [JL] generate manual sentiment analysis requirements from
    description of linguistic capabilities from checklist paper.

  + [JL] for each capability for testing NLP task, how do we extract
    its requirements from the description and use them for finding the
    most relevant data instances in dtaset.
  
  + [JL] manually generate more fine grained word categories e.g. pos_verb, neg_verb.

  + [JL] generate probability distribution over production rule in
    reference CFG.

  + [JL] given selected production rule in seed input, rank candidate
    production rules using the probability distribution.

  + [JL] generate random sentences using diff_cfg.
  
  + [JL] generate cfg difference given input cfg driven from data.
  
  + [JL] generate random sentences using generated_grammar.
  
  + [JL] generate residual cfg grammar between global and input-driven cfg grammar.

  - [JL] make a diff cfg (diff_cfg) between cfg in
    _results/checklist/sentanal_mft_template_grammar.txt and treebank
    global grammar.
  
  + [JL] generate/write cfg from input sentences.
