\vspace{-6pt}
\section{Related Work}

\MyPara{NLP Testing}
%
% With the increasing use of NLP models, evaluation of NLP models is
% becoming a more important issue. 
Apart from the accuracy-based testing
scheme, recent works have considered model robustness as an
aspect for evaluation. Belinkov and Bisk
\textit{\etal}~\cite{belinkov2018breaknmt} aimed to fail Neural Machine
Translation (NMT) model by intentionally introducing noise in the input
text. Pinjia
\textit{\etal}~\cite{pinjia2020structinvtestingnmt,pinjia2020testnmtrt}
measured the robustness of NMT model by assuming syntactic and semantic relation between input and output. Ribeiro
\textit{\etal}~\cite{ribeiro2018sear} proposed an approach to
generalize semantically equivalent adversarial rules. Rychalska \textit{\etal}~\cite{rychalska2019wildnlp} measured drops in
BLEU by corruption operation, and compared model robustness
based on the amount of the drops. Iyyer
\textit{\etal}~\cite{iyyer2018adversarial} introduced learning-based
model for adversarial data augmentation.

In addition to the
robustness on adversarial set, various other aspects of the NLP model have been
considered for the robustness evaluation. Prabhakaran
\textit{\etal}~\cite{prabhakaran2019fairness} developed an evaluation
framework to detect unintended societal bias in NLP models. Rottger
\textit{\etal}~\cite{rottger2020hatecheck} introduced a functional
test suite for hate speech detection in the NLP model.  Ribeiro
\textit{\etal}~\cite{ribeiro2019consistencyeval} measured logical
consistency of NLP model. However, in this work, we focused on the model evaluation over multiple perspectives and produced debugging information by comparing seed and expanded test cases.

\MyPara{Text Generation}
%
Different data augmentation approaches have been proposed for text
generation. One of methods in this category is easy data augmentation
(EDA)~\cite{weizou2019eda}. It uses simple operations such as synonym
replacement and random swap. Coulombe~\cite{coulombe2018textaugapi}
implements rule-based transformations using regular expressions for
text transformations such as insertion of spelling mistakes, data
alterations, entity names, and abbreviations. Mixup interpolation,
which was introduced in computer vision category, was implemented in
text domain~\cite{hongyu2019dataaugmixup}. Learning-based language
models has been used to generate text data for multiple
tasks~\cite{qizhe2019unsupdataaug, ateret2019lambda}. While these
approaches focus on obtaining synthetic training data, not testing NLP
model over \lcs,
% they are not able to be used for the capability testing of the NLP model, 
our work generates text data for testing NLP model over \lcs.  In
addition, adversarial text generation methods has been used for
attacking NLP
model~\cite{morris2020textattack,zang2020sememepso,alzantot2018genadvexp,linyang2020bertattack}. Morris \textit{\etal}~\cite{morris2020textattack}
transform input text by leveraging existing methods such as insertion,
deletion and swap of word/character within the similarity-based
constraints. Zang \textit{\etal}~\cite{zang2020sememepso} finds
sememe-based synonyms and generates adversarial examples by the word
substitution. Alzantot \textit{\etal}~\cite{alzantot2018genadvexp}
substitutes word in an input text with its neighboring words in
embedding space that fools an NLP
model. Linyang \textit{\etal}~\cite{linyang2020bertattack} generates
word substitutes with BERT predicted words for attacking an NLP
model. Also, Grammar-based text generation has been also
introduced~\cite{udeshi2019ogma,soremekun2020astraea,maIJCAI2020mtnlp}.
Ogma~\cite{udeshi2019ogma} and Astraea~\cite{soremekun2020astraea}
leverages predefined grammar, and search adversarial examples by
replacing word in an input text with another one that conforms to same
production rule in the grammar until the replacement leads to error in
the model. Ma \textit{\etal}~\cite{maIJCAI2020mtnlp} applies a simple
expansion that inserts an adjective word before noun besides to
replacement of analogy word found in embedding space. Our work
generates text data does not only rely on the word substitution, but
also changes diverse structures from the input text. In addition, we
generates text conforming to same context of input text and its
corresponding \lc by investigating its semantic and syntax.

\MyPara{Linguistic Capability Evaluation}
%
Wang \textit{\etal}~\cite{wang2018glue, wang2019superglue} proposed
multiple diagnostic datasets to evaluate NLP models 
% . These datasets
% evaluate NLP model's ability to understand input sentence
via natural language inference problems. More recently, \Cklst proposed an evaluation
method of input-output behavior defined as \lcs. \Cklst generates
behavior-guided inputs for validating the
behaviors.~\cite{marcoACL2020checklist}. Unlike prior work that relies on manual
test case generation, we used structural information in text to
generate test cases automatically.

\MyPara{NLP Model Debugging}
%
Researchers have been explaining NLP model prediction and
analyzing it for debugging the model. Ribeiro
\textit{\etal}~\cite{ribeiroSG16lime} evaluated model prediction guided by human feedback providing relevance scores for words on the model prediction. 
Interactive error analysis~\cite{wu2019errudite} also has been proposed to evaluate
model robustness. Zylberajch~\cite{zylberajch2021hildif} used influence functions to generate model explanation, and it enables interactive debugging incorporating humans feedback
explanation.
Lertvittaya~\cite{lertvittayakumjorn2020find} proposed
an approach to understand behavior of text classifier model and improve the
model by disabling irrelevant hidden features. In this work, \tool
is useful for identifying the sources of model failure as shown in RQ4.


% [1] Li Z, Ma X, Xu C, et al. Structural coverage criteria for neural networks could be misleading[C]//2019 IEEE/ACM 41st International Conference on Software Engineering: New Ideas and Emerging Results (ICSE-NIER). IEEE, 2019: 89-92.

% [2] Harel-Canada F, Wang L, Gulzar M A, et al. Is neuron coverage a meaningful measure for testing deep neural networks?[C]//Proceedings of the 28th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering. 2020: 851-862.

% [3] Yan S, Tao G, Liu X, et al. Correlations between deep neural network model coverage criteria and model quality[C]//Proceedings of the 28th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering. 2020: 775-787.

% [4] Chen J, Yan M, Wang Z, et al. Deep neural network test coverage: How far are we?[J]. arXiv preprint arXiv:2010.04946, 2020.
% [5] Xie Q, Dai Z, Hovy E, et al. Unsupervised data augmentation for consistency training[J]. Advances in Neural Information Processing Systems, 2020, 33: 6256-6268. 

% [6] Coulombe C. Text data augmentation made simple by leveraging nlp cloud apis[J]. arXiv preprint arXiv:1812.04718, 2018. 

% [7] Wei J, Zou K. Eda: Easy data augmentation techniques for boosting performance on text classification tasks[J]. arXiv preprint arXiv:1901.11196, 2019. 

% [8] Guo H, Mao Y, Zhang R. Augmenting data with mixup for sentence classification: An empirical study[J]. arXiv preprint arXiv:1905.08941, 2019. 

% [9] Anaby-Tavor A, Carmeli B, Goldbraich E, et al. Do not have enough data? Deep learning to the rescue![C]//Proceedings of the AAAI Conference on Artificial Intelligence. 2020, 34(05): 7383-7390.
