
IEEEfull.bib
V1.12 (2007/01/11)
Copyright (c) 2002-2007 by Michael Shell
See: http://www.michaelshell.org/
for current contact information.

BibTeX bibliography string definitions of the FULL titles of
IEEE journals and magazines and online publications.

This file is designed for bibliography styles that require 
full-length titles and is not for use in bibliographies that
abbreviate titles.

Support sites:
http://www.michaelshell.org/tex/ieeetran/
http://www.ctan.org/tex-archive/macros/latex/contrib/IEEEtran/
and/or
http://www.ieee.org/

Special thanks to Laura Hyslop and ken Rawson of IEEE for their help
in obtaining the information needed to compile this file. Also,
Volker Kuhlmann and Moritz Borgmann kindly provided some corrections
and additions.

*************************************************************************
Legal Notice:
This code is offered as-is without any warranty either expressed or
implied; without even the implied warranty of MERCHANTABILITY or
FITNESS FOR A PARTICULAR PURPOSE! 
User assumes all risk.
In no event shall IEEE or any contributor to this code be liable for
any damages or losses, including, but not limited to, incidental,
consequential, or any other damages, resulting from the use or misuse
of any information contained here.

All comments are the opinions of their respective authors and are not
necessarily endorsed by the IEEE.

This work is distributed under the LaTeX Project Public License (LPPL)
( http://www.latex-project.org/ ) version 1.3, and may be freely used,
distributed and modified. A copy of the LPPL, version 1.3, is included
in the base LaTeX documentation of all distributions of LaTeX released
2003/12/01 or later.
Retain all contribution notices and credits.
** Modified files should be clearly indicated as such, including  **
** renaming them and changing author support contact information. **

File list of work: IEEEabrv.bib, IEEEfull.bib, IEEEexample.bib,
                   IEEEtran.bst, IEEEtranS.bst, IEEEtranSA.bst,
                   IEEEtranN.bst, IEEEtranSN.bst, IEEEtran_bst_HOWTO.pdf
*************************************************************************


USAGE:

\bibliographystyle{mybstfile}
\bibliography{IEEEfull,mybibfile}

where the IEEE titles in the .bib database entries use the strings
defined here. e.g.,


   journal = IEEE_J_AC,


to yield "{IEEE} Transactions on Automatic Control"


WARNING: IEEE uses abbreviated journal titles in their bibliographies!
Because this file provides the full titles, you should NOT use this file
for work that is to be submitted to the IEEE.

For IEEE work, you should use the abbreviated titles provided in the
companion file, IEEEabrv.bib.


** NOTES **

 1. Journals have been grouped according to subject in order to make it
    easier to locate and extract the definitions for related journals - 
    as most works use references that are confined to a single topic.
    Magazines are listed in straight alphabetical order.

 2. String names are closely based on IEEE's own internal acronyms.

 3. Older, out-of-print IEEE titles are included (but not including titles
    dating prior to IEEE's formation from the IRE and AIEE in 1963).






IEEE Journals 



aerospace and military
@STRING{IEEE_J_AES        = "{IEEE} Transactions on Aerospace and Electronic Systems"}
@STRING{IEEE_J_ANE        = "{IEEE} Transactions on Aerospace and Navigational Electronics"}
@STRING{IEEE_J_ANNE       = "{IEEE} Transactions on Aeronautical and Navigational Electronics"}
@STRING{IEEE_J_AS         = "{IEEE} Transactions on Aerospace"}
@STRING{IEEE_J_AIRE       = "{IEEE} Transactions on Airborne Electronics"}
@STRING{IEEE_J_MIL        = "{IEEE} Transactions on Military Electronics"}



autos, transportation and vehicles (non-aerospace)
@STRING{IEEE_J_ITS        = "{IEEE} Transactions on Intelligent Transportation Systems"}
@STRING{IEEE_J_VT         = "{IEEE} Transactions on Vehicular Technology"}
@STRING{IEEE_J_VC         = "{IEEE} Transactions on Vehicular Communications"}



circuits, signals, systems, audio and controls
@STRING{IEEE_J_SPL        = "{IEEE} Signal Processing Letters"}
@STRING{IEEE_J_ASSP       = "{IEEE} Transactions on Acoustics, Speech, and Signal Processing"}
@STRING{IEEE_J_AU         = "{IEEE} Transactions on Audio"}
@STRING{IEEE_J_AUEA       = "{IEEE} Transactions on Audio and Electroacoustics"}
@STRING{IEEE_J_AC         = "{IEEE} Transactions on Automatic Control"}
@STRING{IEEE_J_CAS        = "{IEEE} Transactions on Circuits and Systems"}
@STRING{IEEE_J_CASVT      = "{IEEE} Transactions on Circuits and Systems for Video Technology"}
@STRING{IEEE_J_CASI       = "{IEEE} Transactions on Circuits and Systems---Part {I}: Fundamental Theory and Applications"}
@STRING{IEEE_J_CASII      = "{IEEE} Transactions on Circuits and Systems---Part {II}: Analog and Digital Signal Processing"}
in 2004 CASI and CASII renamed part title to CASI_RP and CASII_EB, respectively.
@STRING{IEEE_J_CASI_RP    = "{IEEE} Transactions on Circuits and Systems---Part {I}: Regular Papers"}
@STRING{IEEE_J_CASII_EB   = "{IEEE} Transactions on Circuits and Systems---Part {II}: Express Briefs"}
@STRING{IEEE_J_CT         = "{IEEE} Transactions on Circuit Theory"}
@STRING{IEEE_J_CST        = "{IEEE} Transactions on Control Systems Technology"}
@STRING{IEEE_J_SP         = "{IEEE} Transactions on Signal Processing"}
@STRING{IEEE_J_SU         = "{IEEE} Transactions on Sonics and Ultrasonics"}
@STRING{IEEE_J_SAP        = "{IEEE} Transactions on Speech and Audio Processing"}
@STRING{IEEE_J_UE         = "{IEEE} Transactions on Ultrasonics Engineering"}
@STRING{IEEE_J_UFFC       = "{IEEE} Transactions on Ultrasonics, Ferroelectrics, and Frequency Control"}



communications
@STRING{IEEE_J_COML       = "{IEEE} Communications Letters"}
@STRING{IEEE_J_JSAC       = "{IEEE} Journal on Selected Areas in Communications"}
@STRING{IEEE_J_COM        = "{IEEE} Transactions on Communications"}
@STRING{IEEE_J_COMT       = "{IEEE} Transactions on Communication Technology"}
@STRING{IEEE_J_WCOM       = "{IEEE} Transactions on Wireless Communications"}



components, packaging and manufacturing
@STRING{IEEE_J_ADVP       = "{IEEE} Transactions on Advanced Packaging"}
@STRING{IEEE_J_CHMT       = "{IEEE} Transactions on Components, Hybrids and Manufacturing Technology"}
@STRING{IEEE_J_CPMTA      = "{IEEE} Transactions on Components, Packaging and Manufacturing Technology---Part {A}"}
@STRING{IEEE_J_CPMTB      = "{IEEE} Transactions on Components, Packaging and Manufacturing Technology---Part {B}: Advanced Packaging"}
@STRING{IEEE_J_CPMTC      = "{IEEE} Transactions on Components, Packaging and Manufacturing Technology---Part {C}: Manufacturing"}
@STRING{IEEE_J_CAPT       = "{IEEE} Transactions on Components and Packaging Technology"}
@STRING{IEEE_J_CAPTS      = "{IEEE} Transactions on Components and Packaging Technologies"}
@STRING{IEEE_J_CPART      = "{IEEE} Transactions on Component Parts"}
@STRING{IEEE_J_EPM        = "{IEEE} Transactions on Electronics Packaging Manufacturing"}
@STRING{IEEE_J_MFT        = "{IEEE} Transactions on Manufacturing Technology"}
@STRING{IEEE_J_PHP        = "{IEEE} Transactions on Parts, Hybrids and Packaging"}
@STRING{IEEE_J_PMP        = "{IEEE} Transactions on Parts, Materials and Packaging"}



CAD
@STRING{IEEE_J_TCAD       = "{IEEE} Journal on Technology in Computer Aided Design"}
@STRING{IEEE_J_CAD        = "{IEEE} Transactions on Computer-Aided Design of Integrated Circuits and Systems"}



coding, data, information, knowledge
@STRING{IEEE_J_IT         = "{IEEE} Transactions on Information Theory"}
@STRING{IEEE_J_KDE        = "{IEEE} Transactions on Knowledge and Data Engineering"}



computers, computation, networking and software
@STRING{IEEE_J_C          = "{IEEE} Transactions on Computers"}
@STRING{IEEE_J_CAL        = "{IEEE} Computer Architecture Letters"}
@STRING{IEEE_J_DSC        = "{IEEE} Transactions on Dependable and Secure Computing"}
@STRING{IEEE_J_ECOMP      = "{IEEE} Transactions on Electronic Computers"}
@STRING{IEEE_J_EVC        = "{IEEE} Transactions on Evolutionary Computation"}
@STRING{IEEE_J_FUZZ       = "{IEEE} Transactions on Fuzzy Systems"}
@STRING{IEEE_J_IFS        = "{IEEE} Transactions on Information Forensics and Security"}
@STRING{IEEE_J_MC         = "{IEEE} Transactions on Mobile Computing"}
@STRING{IEEE_J_NET        = "{IEEE/ACM} Transactions on Networking"}
@STRING{IEEE_J_NN         = "{IEEE} Transactions on Neural Networks"}
@STRING{IEEE_J_PDS        = "{IEEE} Transactions on Parallel and Distributed Systems"}
@STRING{IEEE_J_SE         = "{IEEE} Transactions on Software Engineering"}



computer graphics, imaging, and multimedia
@STRING{IEEE_J_JDT        = "{IEEE/OSA} Journal of Display Technology"}
@STRING{IEEE_J_IP         = "{IEEE} Transactions on Image Processing"}
@STRING{IEEE_J_MM         = "{IEEE} Transactions on Multimedia"}
@STRING{IEEE_J_VCG        = "{IEEE} Transactions on Visualization and Computer Graphics"}



cybernetics, ergonomics, robots, man-machine, and automation
@STRING{IEEE_J_ASE        = "{IEEE} Transactions on Automation Science and Engineering"}
@STRING{IEEE_J_JRA        = "{IEEE} Journal of Robotics and Automation"}
@STRING{IEEE_J_HFE        = "{IEEE} Transactions on Human Factors in Electronics"}
@STRING{IEEE_J_MMS        = "{IEEE} Transactions on Man-Machine Systems"}
@STRING{IEEE_J_PAMI       = "{IEEE} Transactions on Pattern Analysis and Machine Intelligence"}
in 1989 JRA became RA
in August 2004, RA split into ASE and RO
@STRING{IEEE_J_RA         = "{IEEE} Transactions on Robotics and Automation"}
@STRING{IEEE_J_RO         = "{IEEE} Transactions on Robotics"}
@STRING{IEEE_J_SMC        = "{IEEE} Transactions on Systems, Man, and Cybernetics"}
@STRING{IEEE_J_SMCA       = "{IEEE} Transactions on Systems, Man, and Cybernetics---Part {A}: Systems and Humans"}
@STRING{IEEE_J_SMCB       = "{IEEE} Transactions on Systems, Man, and Cybernetics---Part {B}: Cybernetics"}
@STRING{IEEE_J_SMCC       = "{IEEE} Transactions on Systems, Man, and Cybernetics---Part {C}: Applications and Reviews"}
@STRING{IEEE_J_SSC        = "{IEEE} Transactions on Systems Science and Cybernetics"}



earth, wind, fire and water
@STRING{IEEE_J_GE         = "{IEEE} Transactions on Geoscience Electronics"}
@STRING{IEEE_J_GRS        = "{IEEE} Transactions on Geoscience and Remote Sensing"}
@STRING{IEEE_J_GRSL       = "{IEEE} Geoscience and Remote Sensing Letters"}
@STRING{IEEE_J_OE         = "{IEEE} Journal of Oceanic Engineering"}



education, engineering, history, IEEE, professional
@STRING{IEEE_J_CJECE      = "Canadian Journal of Electrical and Computer Engineering"}
@STRING{IEEE_J_PROC       = "Proceedings of the {IEEE}"}
@STRING{IEEE_J_EDU        = "{IEEE} Transactions on Education"}
@STRING{IEEE_J_EM         = "{IEEE} Transactions on Engineering Management"}
@STRING{IEEE_J_EWS        = "{IEEE} Transactions on Engineering Writing and Speech"}
@STRING{IEEE_J_PC         = "{IEEE} Transactions on Professional Communication"}



electromagnetics, antennas, EMI, magnetics and microwave
@STRING{IEEE_J_AWPL       = "{IEEE} Antennas and Wireless Propagation Letters"}
@STRING{IEEE_J_MGWL       = "{IEEE} Microwave and Guided Wave Letters"}
@STRING{IEEE_J_MWCL       = "{IEEE} Microwave and Wireless Components Letters"}
@STRING{IEEE_J_AP         = "{IEEE} Transactions on Antennas and Propagation"}
@STRING{IEEE_J_EMC        = "{IEEE} Transactions on Electromagnetic Compatibility"}
@STRING{IEEE_J_MAG        = "{IEEE} Transactions on Magnetics"}
@STRING{IEEE_J_MTT        = "{IEEE} Transactions on Microwave Theory and Techniques"}
@STRING{IEEE_J_RFI        = "{IEEE} Transactions on Radio Frequency Interference"}
@STRING{IEEE_J_TJMJ       = "{IEEE} Translation Journal on Magnetics in Japan"}



energy and power
@STRING{IEEE_J_EC         = "{IEEE} Transactions on Energy Conversion"}
@STRING{IEEE_J_PEL        = "{IEEE} Power Electronics Letters"}
@STRING{IEEE_J_PWRAS      = "{IEEE} Transactions on Power Apparatus and Systems"}
@STRING{IEEE_J_PWRD       = "{IEEE} Transactions on Power Delivery"}
@STRING{IEEE_J_PWRE       = "{IEEE} Transactions on Power Electronics"}
@STRING{IEEE_J_PWRS       = "{IEEE} Transactions on Power Systems"}



industrial, commercial and consumer
@STRING{IEEE_J_APPIND     = "{IEEE} Transactions on Applications and Industry"}
@STRING{IEEE_J_BC         = "{IEEE} Transactions on Broadcasting"}
@STRING{IEEE_J_BCTV       = "{IEEE} Transactions on Broadcast and Television Receivers"}
@STRING{IEEE_J_CE         = "{IEEE} Transactions on Consumer Electronics"}
@STRING{IEEE_J_IE         = "{IEEE} Transactions on Industrial Electronics"}
@STRING{IEEE_J_IECI       = "{IEEE} Transactions on Industrial Electronics and Control Instrumentation"}
@STRING{IEEE_J_IA         = "{IEEE} Transactions on Industry Applications"}
@STRING{IEEE_J_IGA        = "{IEEE} Transactions on Industry and General Applications"}
@STRING{IEEE_J_IINF       = "{IEEE} Transactions on Industrial Informatics"}
@STRING{IEEE_J_PSE        = "{IEEE} Journal of Product Safety Engineering"}



instrumentation and measurement
@STRING{IEEE_J_IM         = "{IEEE} Transactions on Instrumentation and Measurement"}



insulation and materials
@STRING{IEEE_J_JEM        = "{IEEE/TMS} Journal of Electronic Materials"}
@STRING{IEEE_J_DEI        = "{IEEE} Transactions on Dielectrics and Electrical Insulation"}
@STRING{IEEE_J_EI         = "{IEEE} Transactions on Electrical Insulation"}



mechanical
@STRING{IEEE_J_MECH       = "{IEEE/ASME} Transactions on Mechatronics"}
@STRING{IEEE_J_MEMS       = "{IEEE/ASME} Journal of Microelectromechanical Systems"}



medical and biological
@STRING{IEEE_J_BME        = "{IEEE} Transactions on Biomedical Engineering"}
Note: The B-ME journal later dropped the hyphen and became the BME.
@STRING{IEEE_J_B-ME       = "{IEEE} Transactions on Bio-Medical Engineering"}
@STRING{IEEE_J_BMELC      = "{IEEE} Transactions on Bio-Medical Electronics"}
@STRING{IEEE_J_CBB        = "{IEEE/ACM} Transactions on Computational Biology and Bioinformatics"}
@STRING{IEEE_J_ITBM       = "{IEEE} Transactions on Information Technology in Biomedicine"}
@STRING{IEEE_J_ME         = "{IEEE} Transactions on Medical Electronics"}
@STRING{IEEE_J_MI         = "{IEEE} Transactions on Medical Imaging"}
@STRING{IEEE_J_NB         = "{IEEE} Transactions on NanoBioscience"}
@STRING{IEEE_J_NSRE       = "{IEEE} Transactions on Neural Systems and Rehabilitation Engineering"}
@STRING{IEEE_J_RE         = "{IEEE} Transactions on Rehabilitation Engineering"}



optics, lightwave and photonics
@STRING{IEEE_J_PTL        = "{IEEE} Photonics Technology Letters"}
@STRING{IEEE_J_JLT        = "{IEEE/OSA} Journal of Lightwave Technology"}



physics, electrons, nanotechnology, nuclear and quantum electronics
@STRING{IEEE_J_EDL        = "{IEEE} Electron Device Letters"}
@STRING{IEEE_J_JQE        = "{IEEE} Journal of Quantum Electronics"}
@STRING{IEEE_J_JSTQE      = "{IEEE} Journal of Selected Topics in Quantum Electronics"}
@STRING{IEEE_J_ED         = "{IEEE} Transactions on Electron Devices"}
@STRING{IEEE_J_NANO       = "{IEEE} Transactions on Nanotechnology"}
@STRING{IEEE_J_NS         = "{IEEE} Transactions on Nuclear Science"}
@STRING{IEEE_J_PS         = "{IEEE} Transactions on Plasma Science"}



reliability
@STRING{IEEE_J_DMR        = "{IEEE} Transactions on Device and Materials Reliability"}
@STRING{IEEE_J_R          = "{IEEE} Transactions on Reliability"}



semiconductors, superconductors, electrochemical and solid state
@STRING{IEEE_J_ESSL       = "{IEEE/ECS} Electrochemical and Solid-State Letters"}
@STRING{IEEE_J_JSSC       = "{IEEE} Journal of Solid-State Circuits"}
@STRING{IEEE_J_ASC        = "{IEEE} Transactions on Applied Superconductivity"}
@STRING{IEEE_J_SM         = "{IEEE} Transactions on Semiconductor Manufacturing"}



sensors
@STRING{IEEE_J_SENSOR     = "{IEEE} Sensors Journal"}



VLSI
@STRING{IEEE_J_VLSI       = "{IEEE} Transactions on Very Large Scale Integration ({VLSI}) Systems"}






IEEE Magazines



@STRING{IEEE_M_AES        = "{IEEE} Aerospace and Electronics Systems Magazine"}
@STRING{IEEE_M_HIST       = "{IEEE} Annals of the History of Computing"}
@STRING{IEEE_M_AP         = "{IEEE} Antennas and Propagation Magazine"}
@STRING{IEEE_M_ASSP       = "{IEEE} {ASSP} Magazine"}
@STRING{IEEE_M_CD         = "{IEEE} Circuits and Devices Magazine"}
@STRING{IEEE_M_CAS        = "{IEEE} Circuits and Systems Magazine"}
@STRING{IEEE_M_COM        = "{IEEE} Communications Magazine"}
@STRING{IEEE_M_COMSOC     = "{IEEE} Communications Society Magazine"}
@STRING{IEEE_M_CIM        = "{IEEE} Computational Intelligence Magazine"}
CSEM changed to CSE in 1999
@STRING{IEEE_M_CSE        = "{IEEE} Computing in Science and Engineering"}
@STRING{IEEE_M_CSEM       = "{IEEE} Computational Science and Engineering Magazine"}
@STRING{IEEE_M_C          = "{IEEE} Computer"}
@STRING{IEEE_M_CAP        = "{IEEE} Computer Applications in Power"}
@STRING{IEEE_M_CGA        = "{IEEE} Computer Graphics and Applications"}
@STRING{IEEE_M_CONC       = "{IEEE} Concurrency"}
@STRING{IEEE_M_CS         = "{IEEE} Control Systems Magazine"}
@STRING{IEEE_M_DTC        = "{IEEE} Design and Test of Computers"}
@STRING{IEEE_M_EI         = "{IEEE} Electrical Insulation Magazine"}
@STRING{IEEE_M_ETR        = "{IEEE} ElectroTechnology Review"}
@STRING{IEEE_M_EMB        = "{IEEE} Engineering in Medicine and Biology Magazine"}
@STRING{IEEE_M_EMR        = "{IEEE} Engineering Management Review"}
@STRING{IEEE_M_EXP        = "{IEEE} Expert"}
@STRING{IEEE_M_IA         = "{IEEE} Industry Applications Magazine"}
@STRING{IEEE_M_IM         = "{IEEE} Instrumentation and Measurement Magazine"}
@STRING{IEEE_M_IS         = "{IEEE} Intelligent Systems"}
@STRING{IEEE_M_IC         = "{IEEE} Internet Computing"}
@STRING{IEEE_M_ITP        = "{IEEE} {IT} Professional"}
@STRING{IEEE_M_MICRO      = "{IEEE} Micro"}
@STRING{IEEE_M_MW         = "{IEEE} Microwave Magazine"}
@STRING{IEEE_M_MM         = "{IEEE} Multimedia"}
@STRING{IEEE_M_NET        = "{IEEE} Network"}
@STRING{IEEE_M_PCOM       = "{IEEE} Personal Communications Magazine"}
@STRING{IEEE_M_POT        = "{IEEE} Potentials"}
CAP and PER merged to form PE in 2003
@STRING{IEEE_M_PE         = "{IEEE} Power and Energy Magazine"}
@STRING{IEEE_M_PER        = "{IEEE} Power Engineering Review"}
@STRING{IEEE_M_PVC        = "{IEEE} Pervasive Computing"}
@STRING{IEEE_M_RA         = "{IEEE} Robotics and Automation Magazine"}
@STRING{IEEE_M_SAP        = "{IEEE} Security and Privacy"}
@STRING{IEEE_M_SP         = "{IEEE} Signal Processing Magazine"}
@STRING{IEEE_M_S          = "{IEEE} Software"}
@STRING{IEEE_M_SPECT      = "{IEEE} Spectrum"}
@STRING{IEEE_M_TS         = "{IEEE} Technology and Society Magazine"}
@STRING{IEEE_M_VT         = "{IEEE} Vehicular Technology Magazine"}
@STRING{IEEE_M_WC         = "{IEEE} Wireless Communications Magazine"}
@STRING{IEEE_M_TODAY      = "Today's Engineer"}






IEEE Online Publications 



@STRING{IEEE_O_CSTO        = "{IEEE} Communications Surveys and Tutorials"}
@STRING{IEEE_O_DSO         = "{IEEE} Distributed Systems Online"}





--

@InProceedings{recht2019imagenetbias,
  title = 	 {Do {I}mage{N}et Classifiers Generalize to {I}mage{N}et?},
  author =       {Recht, Benjamin and Roelofs, Rebecca and Schmidt, Ludwig and Shankar, Vaishaal},
  booktitle = 	 {Proceedings of the 36th International Conference on Machine Learning},
  pages = 	 {5389--5400},
  year = 	 {2019},
  editor = 	 {Chaudhuri, Kamalika and Salakhutdinov, Ruslan},
  volume = 	 {97},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {09--15 Jun},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v97/recht19a/recht19a.pdf},
  url = 	 {https://proceedings.mlr.press/v97/recht19a.html},
  abstract = 	 {We build new test sets for the CIFAR-10 and ImageNet datasets. Both benchmarks have been the focus of intense research for almost a decade, raising the danger of overfitting to excessively re-used test sets. By closely following the original dataset creation processes, we test to what extent current classification models generalize to new data. We evaluate a broad range of models and find accuracy drops of 3% - 15% on CIFAR-10 and 11% - 14% on ImageNet. However, accuracy gains on the original test sets translate to larger gains on the new test sets. Our results suggest that the accuracy drops are not caused by adaptivity, but by the models’ inability to generalize to slightly "harder" images than those found in the original test sets.}
}

@inproceedings{wu2019errudite,
    title = "{E}rrudite: Scalable, Reproducible, and Testable Error Analysis",
    author = "Wu, Tongshuang  and
      Ribeiro, Marco Tulio  and
      Heer, Jeffrey  and
      Weld, Daniel",
    booktitle = "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P19-1073",
    doi = "10.18653/v1/P19-1073",
    pages = "747--763",
    abstract = "Though error analysis is crucial to understanding and improving NLP models, the common practice of manual, subjective categorization of a small sample of errors can yield biased and incomplete conclusions. This paper codifies model and task agnostic principles for informative error analysis, and presents Errudite, an interactive tool for better supporting this process. First, error groups should be precisely defined for reproducibility; Errudite supports this with an expressive domain-specific language. Second, to avoid spurious conclusions, a large set of instances should be analyzed, including both positive and negative examples; Errudite enables systematic grouping of relevant instances with filtering queries. Third, hypotheses about the cause of errors should be explicitly tested; Errudite supports this via automated counterfactual rewriting. We validate our approach with a user study, finding that Errudite (1) enables users to perform high quality and reproducible error analyses with less effort, (2) reveals substantial ambiguities in prior published error analyses practices, and (3) enhances the error analysis experience by allowing users to test and revise prior beliefs.",
}

@inproceedings{marcoACL2020checklist,  
 author = {Marco Tulio Ribeiro and Tongshuang Wu and Carlos Guestrin and Sameer Singh},  
 title = {Beyond Accuracy: Behavioral Testing of NLP models with CheckList},  
 booktitle = {Association for Computational Linguistics (ACL)},  
 year = {2020}
}

@inproceedings{ribeiro2018sear,
    title = "Semantically Equivalent Adversarial Rules for Debugging {NLP} models",
    author = "Ribeiro, Marco Tulio  and
      Singh, Sameer  and
      Guestrin, Carlos",
    booktitle = "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = jul,
    year = "2018",
    address = "Melbourne, Australia",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P18-1079",
    doi = "10.18653/v1/P18-1079",
    pages = "856--865",
    abstract = "Complex machine learning models for NLP are often brittle, making different predictions for input instances that are extremely similar semantically. To automatically detect this behavior for individual instances, we present semantically equivalent adversaries (SEAs) {--} semantic-preserving perturbations that induce changes in the model{'}s predictions. We generalize these adversaries into semantically equivalent adversarial rules (SEARs) {--} simple, universal replacement rules that induce adversaries on many instances. We demonstrate the usefulness and flexibility of SEAs and SEARs by detecting bugs in black-box state-of-the-art models for three domains: machine comprehension, visual question-answering, and sentiment analysis. Via user studies, we demonstrate that we generate high-quality local adversaries for more instances than humans, and that SEARs induce four times as many mistakes as the bugs discovered by human experts. SEARs are also actionable: retraining models using data augmentation significantly reduces bugs, while maintaining accuracy.",
}

@article{belinkov2018breaknmt,
  author    = {Yonatan Belinkov and
               Yonatan Bisk},
  title     = {Synthetic and Natural Noise Both Break Neural Machine Translation},
  journal   = {CoRR},
  volume    = {abs/1711.02173},
  year      = {2017},
  url       = {http://arxiv.org/abs/1711.02173},
  eprinttype = {arXiv},
  eprint    = {1711.02173},
  timestamp = {Mon, 13 Aug 2018 16:47:18 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1711-02173.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@InProceedings{rychalska2019wildnlp,
author="Rychalska, Barbara
and Basaj, Dominika
and Gosiewska, Alicja
and Biecek, Przemys{\l}aw",
editor="Gedeon, Tom
and Wong, Kok Wai
and Lee, Minho",
title="Models in the Wild: On Corruption Robustness of Neural NLP Systems",
booktitle="Neural Information Processing",
year="2019",
publisher="Springer International Publishing",
address="Cham",
pages="235--247",
abstract="Natural Language Processing models lack a unified approach to robustness testing. In this paper we introduce WildNLP - a framework for testing model stability in a natural setting where text corruptions such as keyboard errors or misspelling occur. We compare robustness of deep learning models from 4 popular NLP tasks: Q{\&}A, NLI, NER and Sentiment Analysis by testing their performance on aspects introduced in the framework. In particular, we focus on a comparison between recent state-of-the-art text representations and non-contextualized word embeddings. In order to improve robustness, we perform adversarial training on selected aspects and check its transferability to the improvement of models with various corruption types. We find that the high performance of models does not ensure sufficient robustness, although modern embedding techniques help to improve it. We release the code of WildNLP framework for the community.",
isbn="978-3-030-36718-3"
}

@inproceedings{iyyer2018adversarial,
    title = "Adversarial Example Generation with Syntactically Controlled Paraphrase Networks",
    author = "Iyyer, Mohit  and
      Wieting, John  and
      Gimpel, Kevin  and
      Zettlemoyer, Luke",
    booktitle = "Proceedings of the 2018 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers)",
    month = jun,
    year = "2018",
    address = "New Orleans, Louisiana",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/N18-1170",
    doi = "10.18653/v1/N18-1170",
    pages = "1875--1885",
    abstract = "We propose syntactically controlled paraphrase networks (SCPNs) and use them to generate adversarial examples. Given a sentence and a target syntactic form (e.g., a constituency parse), SCPNs are trained to produce a paraphrase of the sentence with the desired syntax. We show it is possible to create training data for this task by first doing backtranslation at a very large scale, and then using a parser to label the syntactic transformations that naturally occur during this process. Such data allows us to train a neural encoder-decoder model with extra inputs to specify the target syntax. A combination of automated and human evaluations show that SCPNs generate paraphrases that follow their target specifications without decreasing paraphrase quality when compared to baseline (uncontrolled) paraphrase systems. Furthermore, they are more capable of generating syntactically adversarial examples that both (1) {``}fool{''} pretrained models and (2) improve the robustness of these models to syntactic variation when used to augment their training data.",
}

@article{prabhakaran2019fairness,
  author    = {Vinodkumar Prabhakaran and
               Ben Hutchinson and
               Margaret Mitchell},
  title     = {Perturbation Sensitivity Analysis to Detect Unintended Model Biases},
  journal   = {CoRR},
  volume    = {abs/1910.04210},
  year      = {2019},
  url       = {http://arxiv.org/abs/1910.04210},
  eprinttype = {arXiv},
  eprint    = {1910.04210},
  timestamp = {Wed, 16 Oct 2019 16:25:53 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1910-04210.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{rottger2020hatecheck,
  author    = {Paul R{\"{o}}ttger and
               Bertram Vidgen and
               Dong Nguyen and
               Zeerak Waseem and
               Helen Z. Margetts and
               Janet B. Pierrehumbert},
  title     = {HateCheck: Functional Tests for Hate Speech Detection Models},
  journal   = {CoRR},
  volume    = {abs/2012.15606},
  year      = {2020},
  url       = {https://arxiv.org/abs/2012.15606},
  eprinttype = {arXiv},
  eprint    = {2012.15606},
  timestamp = {Fri, 15 Jan 2021 16:55:50 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2012-15606.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{ribeiro2019consistencyeval,
    title = "Are Red Roses Red? Evaluating Consistency of Question-Answering Models",
    author = "Ribeiro, Marco Tulio  and
      Guestrin, Carlos  and
      Singh, Sameer",
    booktitle = "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P19-1621",
    doi = "10.18653/v1/P19-1621",
    pages = "6174--6184",
    abstract = "Although current evaluation of question-answering systems treats predictions in isolation, we need to consider the relationship between predictions to measure true understanding. A model should be penalized for answering {``}no{''} to {``}Is the rose red?{''} if it answers {``}red{''} to {``}What color is the rose?{''}. We propose a method to automatically extract such implications for instances from two QA datasets, VQA and SQuAD, which we then use to evaluate the consistency of models. Human evaluation shows these generated implications are well formed and valid. Consistency evaluation provides crucial insights into gaps in existing models, while retraining with implication-augmented data improves consistency on both synthetic and human-generated implications.",
}

@article{ribeiroSG16lime,
  author    = {Marco T{\'{u}}lio Ribeiro and
               Sameer Singh and
               Carlos Guestrin},
  title     = {"Why Should {I} Trust You?": Explaining the Predictions of Any Classifier},
  journal   = {CoRR},
  volume    = {abs/1602.04938},
  year      = {2016},
  url       = {http://arxiv.org/abs/1602.04938},
  eprinttype = {arXiv},
  eprint    = {1602.04938},
  timestamp = {Mon, 13 Aug 2018 16:49:09 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/RibeiroSG16.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{wang2018glue,
  author    = {Alex Wang and
               Amanpreet Singh and
               Julian Michael and
               Felix Hill and
               Omer Levy and
               Samuel R. Bowman},
  title     = {{GLUE:} {A} Multi-Task Benchmark and Analysis Platform for Natural
               Language Understanding},
  journal   = {CoRR},
  volume    = {abs/1804.07461},
  year      = {2018},
  url       = {http://arxiv.org/abs/1804.07461},
  eprinttype = {arXiv},
  eprint    = {1804.07461},
  timestamp = {Mon, 13 Aug 2018 16:46:56 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1804-07461.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}



@article{devlin2019bert,
  author    = {Jacob Devlin and
               Ming{-}Wei Chang and
               Kenton Lee and
               Kristina Toutanova},
  title     = {{BERT:} Pre-training of Deep Bidirectional Transformers for Language
               Understanding},
  journal   = {CoRR},
  volume    = {abs/1810.04805},
  year      = {2018},
  url       = {http://arxiv.org/abs/1810.04805},
  eprinttype = {arXiv},
  eprint    = {1810.04805},
  timestamp = {Tue, 30 Oct 2018 20:39:56 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1810-04805.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{liu2019roberta,
  author    = {Yinhan Liu and
               Myle Ott and
               Naman Goyal and
               Jingfei Du and
               Mandar Joshi and
               Danqi Chen and
               Omer Levy and
               Mike Lewis and
               Luke Zettlemoyer and
               Veselin Stoyanov},
  title     = {RoBERTa: {A} Robustly Optimized {BERT} Pretraining Approach},
  journal   = {CoRR},
  volume    = {abs/1907.11692},
  year      = {2019},
  url       = {http://arxiv.org/abs/1907.11692},
  eprinttype = {arXiv},
  eprint    = {1907.11692},
  timestamp = {Thu, 01 Aug 2019 08:59:33 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1907-11692.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{sanh2019distilbert,
  title={DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter},
  author={Victor Sanh and Lysandre Debut and Julien Chaumond and Thomas Wolf},
  journal={ArXiv},
  year={2019},
  volume={abs/1910.01108}
}

@article{mitchell1993treebank,
author = {Marcus, Mitchell P. and Marcinkiewicz, Mary Ann and Santorini, Beatrice},
title = {Building a Large Annotated Corpus of English: The Penn Treebank},
year = {1993},
issue_date = {June 1993},
publisher = {MIT Press},
address = {Cambridge, MA, USA},
volume = {19},
number = {2},
issn = {0891-2017},
journal = {Comput. Linguist.},
month = {jun},
pages = {313–330},
numpages = {18}
}

@online{nltkTreebankCorporaWebPage,
  author = {Sphinx and NLTK Theme},
  title = {NLTK Documentation},
  key = {NLTKDocumentationWebPage},
  year = {2021},
  note = {\url{https://www.nltk.org/howto/corpus.html}},
}

@inproceedings{kitaev2019multilingual,
    title = "Multilingual Constituency Parsing with Self-Attention and Pre-Training",
    author = "Kitaev, Nikita  and
      Cao, Steven  and
      Klein, Dan",
    booktitle = "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/P19-1340",
    doi = "10.18653/v1/P19-1340",
    pages = "3499--3505",
}

@inproceedings{kitaev2018constituency,
    title = "Constituency Parsing with a Self-Attentive Encoder",
    author = "Kitaev, Nikita  and
      Klein, Dan",
    booktitle = "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = jul,
    year = "2018",
    address = "Melbourne, Australia",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/P18-1249",
    doi = "10.18653/v1/P18-1249",
    pages = "2676--2686",
}

@inproceedings{baccianella2010sentiwordnet,
    title = "{S}enti{W}ord{N}et 3.0: An Enhanced Lexical Resource for Sentiment Analysis and Opinion Mining",
    author = "Baccianella, Stefano  and
      Esuli, Andrea  and
      Sebastiani, Fabrizio",
    booktitle = "Proceedings of the Seventh International Conference on Language Resources and Evaluation ({LREC}'10)",
    month = may,
    year = "2010",
    address = "Valletta, Malta",
    publisher = "European Language Resources Association (ELRA)",
    url = "http://www.lrec-conf.org/proceedings/lrec2010/pdf/769_Paper.pdf",
    abstract = "In this work we present SENTIWORDNET 3.0, a lexical resource explicitly devised for supporting sentiment classification and opinion mining applications. SENTIWORDNET 3.0 is an improved version of SENTIWORDNET 1.0, a lexical resource publicly available for research purposes, now currently licensed to more than 300 research groups and used in a variety of research projects worldwide. Both SENTIWORDNET 1.0 and 3.0 are the result of automatically annotating all WORDNET synsets according to their degrees of positivity, negativity, and neutrality. SENTIWORDNET 1.0 and 3.0 differ (a) in the versions of WORDNET which they annotate (WORDNET 2.0 and 3.0, respectively), (b) in the algorithm used for automatically annotating WORDNET, which now includes (additionally to the previous semi-supervised learning step) a random-walk step for refining the scores. We here discuss SENTIWORDNET 3.0, especially focussing on the improvements concerning aspect (b) that it embodies with respect to version 1.0. We also report the results of evaluating SENTIWORDNET 3.0 against a fragment of WORDNET 3.0 manually annotated for positivity, negativity, and neutrality; these results indicate accuracy improvements of about 20{\%} with respect to SENTIWORDNET 1.0.",
}

@Article{mihaela2017sentiwordnetlabel,
AUTHOR = {Colhon, Mihaela and Vlăduţescu, Ştefan and Negrea, Xenia},
TITLE = {How Objective a Neutral Word Is? A Neutrosophic Approach for the Objectivity Degrees of Neutral Words},
JOURNAL = {Symmetry},
VOLUME = {9},
YEAR = {2017},
NUMBER = {11},
ARTICLE-NUMBER = {280},
URL = {https://www.mdpi.com/2073-8994/9/11/280},
ISSN = {2073-8994},
ABSTRACT = {In the latest studies concerning the sentiment polarity of words, the authors mostly consider the positive and negative constructions, without paying too much attention to the neutral words, which can have, in fact, significant sentiment degrees. More precisely, not all the neutral words have zero positivity or negativity scores, some of them having quite important nonzero scores for these polarities. At this moment, in the literature, a word is considered neutral if its positive and negative scores are equal, which implies two possibilities: (1) zero positive and negative scores; (2) nonzero, but equal positive and negative scores. It is obvious that these cases represent two different categories of neutral words that must be treated separately by a sentiment analysis task. In this paper, we present a comprehensive study about the neutral words applied to English as is developed with the aid of SentiWordNet 3.0: the publicly available lexical resource for opinion mining. We designed our study in order to provide an accurate classification of the so-called “neutral words” described in terms of sentiment scores and using measures from neutrosophy theory. The intended scope is to fill the gap concerning the neutrality aspect by giving precise measurements for the words’ objectivity.},
DOI = {10.3390/sym9110280}
}

@inproceedings{kitaev2019seedparser,
    title = "Multilingual Constituency Parsing with Self-Attention and Pre-Training",
    author = "Kitaev, Nikita  and
      Cao, Steven  and
      Klein, Dan",
    booktitle = "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/P19-1340",
    doi = "10.18653/v1/P19-1340",
    pages = "3499--3505",
}

@inproceedings{kitaev2018seedparser,
    title = "Constituency Parsing with a Self-Attentive Encoder",
    author = "Kitaev, Nikita  and
      Klein, Dan",
    booktitle = "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = jul,
    year = "2018",
    address = "Melbourne, Australia",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/P18-1249",
    doi = "10.18653/v1/P18-1249",
    pages = "2676--2686",
}

@inproceedings{pei2017deepxplore,
	doi = {10.1145/3132747.3132785},
	url = {https://doi.org/10.1145%2F3132747.3132785},
	year = 2017,
	month = {oct},
	publisher = {{ACM}},
	author = {Kexin Pei and Yinzhi Cao and Junfeng Yang and Suman Jana},
	title = {{DeepXplore}}, 
	booktitle = {Proceedings of the 26th Symposium on Operating Systems Principles}
}

@inbook{simin2020denas,
author = {Chen, Simin and Bateni, Soroush and Grandhi, Sampath and Li, Xiaodi and Liu, Cong and Yang, Wei},
title = {DENAS: Automated Rule Generation by Knowledge Extraction from Neural Networks},
year = {2020},
isbn = {9781450370431},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3368089.3409733},
booktitle = {Proceedings of the 28th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
pages = {813–825},
numpages = {13}
}

@inproceedings{patel2018mlevalforsoftware,
author = {Patel, Kayur and Fogarty, James and Landay, James A. and Harrison, Beverly},
title = {Investigating Statistical Machine Learning as a Tool for Software Development},
year = {2008},
isbn = {9781605580111},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1357054.1357160},
doi = {10.1145/1357054.1357160},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {667–676},
numpages = {10},
keywords = {statistical machine learning, software development},
location = {Florence, Italy},
series = {CHI '08}
}



@inproceedings{ma2018deepgauge,
  title={Deepgauge: Multi-granularity testing criteria for deep learning systems},
  author={Ma, Lei and Juefei-Xu, Felix and Zhang, Fuyuan and Sun, Jiyuan and Xue, Minhui and Li, Bo and Chen, Chunyang and Su, Ting and Li, Li and Liu, Yang and others},
  booktitle={Proceedings of the 33rd ACM/IEEE International Conference on Automated Software Engineering},
  pages={120--131},
  year={2018}
}

@ARTICLE{segura2016metamorphictest,
  author={Segura, Sergio and Fraser, Gordon and Sanchez, Ana B. and Ruiz-Cortés, Antonio},
  journal={IEEE Transactions on Software Engineering}, 
  title={A Survey on Metamorphic Testing}, 
  year={2016},
  volume={42},
  number={9},
  pages={805-824},
  doi={10.1109/TSE.2016.2532875}
}

@inproceedings{lime,
  title={" Why should i trust you?" Explaining the predictions of any classifier},
  author={Ribeiro, Marco Tulio and Singh, Sameer and Guestrin, Carlos},
  booktitle={Proceedings of the 22nd ACM SIGKDD international conference on knowledge discovery and data mining},
  pages={1135--1144},
  year={2016}
}
@inproceedings{lemna,
  title={Lemna: Explaining deep learning based security applications},
  author={Guo, Wenbo and Mu, Dongliang and Xu, Jun and Su, Purui and Wang, Gang and Xing, Xinyu},
  booktitle={proceedings of the 2018 ACM SIGSAC conference on computer and communications security},
  pages={364--379},
  year={2018}
}

@article{husnain2021swnvalidity,
  title={A systematic study on the role of SentiWordNet in opinion mining},
  author={Husnain, Mujtaba and Missen, Malik Muhammad Saad and Akhtar, Nadeem and Coustaty, Micka{\"e}l and Mumtaz, Shahzad and Prasath, VB},
  journal={Frontiers of Computer Science},
  volume={15},
  number={4},
  pages={1--19},
  year={2021},
  publisher={Springer}
}

@article{wang2019superglue,
  author    = {Alex Wang and
               Yada Pruksachatkun and
               Nikita Nangia and
               Amanpreet Singh and
               Julian Michael and
               Felix Hill and
               Omer Levy and
               Samuel R. Bowman},
  title     = {SuperGLUE: {A} Stickier Benchmark for General-Purpose Language Understanding
               Systems},
  journal   = {CoRR},
  volume    = {abs/1905.00537},
  year      = {2019},
  url       = {http://arxiv.org/abs/1905.00537},
  eprinttype = {arXiv},
  eprint    = {1905.00537},
  timestamp = {Mon, 27 May 2019 13:15:00 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1905-00537.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{pinjia2020structinvtestingnmt,
  author    = {Pinjia He and
               Clara Meister and
               Zhendong Su},
  title     = {Structure-Invariant Testing for Machine Translation},
  journal   = {CoRR},
  volume    = {abs/1907.08710},
  year      = {2019},
  url       = {http://arxiv.org/abs/1907.08710},
  eprinttype = {arXiv},
  eprint    = {1907.08710},
  timestamp = {Tue, 30 Nov 2021 15:21:24 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1907-08710.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{pinjia2020testnmtrt,
  author    = {Pinjia He and
               Clara Meister and
               Zhendong Su},
  title     = {Testing Machine Translation via Referential Transparency},
  journal   = {CoRR},
  volume    = {abs/2004.10361},
  year      = {2020},
  url       = {https://arxiv.org/abs/2004.10361},
  eprinttype = {arXiv},
  eprint    = {2004.10361},
  timestamp = {Tue, 30 Nov 2021 15:21:24 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2004-10361.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
 }

@inproceedings{socher2013sst,
    title = {Recursive Deep Models for Semantic Compositionality Over a Sentiment Treebank},
    author = {Socher, Richard  and Perelygin, Alex  and      Wu, Jean  and    Chuang, Jason  and  Manning, Christopher D.  and    Ng, Andrew  and   Potts, Christopher},
    booktitle = {Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing},
    year = {2013},
    address = {Seattle, Washington, USA},
    publisher = {Association for Computational Linguistics},
    url = {https://aclanthology.org/D13-1170},
    pages = {1631--1642},
}

@unpublished{spacy,
    AUTHOR = {Honnibal, Matthew and Montani, Ines},
    TITLE  = {{spaCy 2}: Natural language understanding with {B}loom embeddings, convolutional neural networks and incremental parsing},
    YEAR   = {2017},
    Note   = {To appear}
}

@article{zylberajch2021hildif,
  title={HILDIF: Interactive Debugging of NLI Models Using Influence Functions},
  author={Hugo Zylberajch and Piyawat Lertvittayakumjorn and Francesca Toni},
  journal={Proceedings of the First Workshop on Interactive Learning
                  for Natural Language Processing},
  year={2021}
}

@misc{lertvittayakumjorn2020find,
  doi = {10.48550/ARXIV.2010.04987},
  
  url = {https://arxiv.org/abs/2010.04987},
  
  author = {Lertvittayakumjorn, Piyawat and Specia, Lucia and Toni, Francesca},
  
  keywords = {Computation and Language (cs.CL), Human-Computer Interaction (cs.HC), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {FIND: Human-in-the-Loop Debugging Deep Text Classifiers},
  
  publisher = {arXiv},
  
  year = {2020},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

