uniqueness of the test generation over lc
difference metamorphic testing than our work

ours: both label-consistency and LC-consistency
manually discovered label consistency

1. we generate new structure than other work

our work more generally preserves semantic context(capability part)
and grammatical correctness(syntactical part).

==========
Thank you for the comments.

__REVIEW_1&2

>Uniqueness of S^2LCT over prior work (MT-NLP, Astraea, Ogma and
 adversarial methods for NLP models)

S^2LCT is based on a grammar based test case generation method. The
uniqueness of the S^2LCT stems from the following properties: First,
S^2LCT generates new test cases with new and diverse input structures
given the grammar obtained from commonly used large corpus.  Compared
with the method, Astraea and Ogma generates input sentences by
replacing words in an original sentences with other words with same
tag of part-of-speech (POS) conforming to the grammar manually
constructed. In addition, MT-NLP both replaces words and expands input
structure, but the expansion only relies on a addition of adjective
word before noun. In our paper, the structural diversity is shown by
production rule coverage. Second, S^2LCT addresses consistency of
label and linguistic capability (LC). The Ogma does not aim to
preserve the semantic similarity, and it causes label inconsistency in
input generation. In addition, Astraea and MT-NLP manually preserves
label consistency by only relying on limited grammar attributes
(e.g. replacement of noun words). Compared with it, S^2LCT preserves
label and LC consistency by analyzing syntactic and semantic
appropriateness of expanded words in the input sentence. Besides,
S^2LCT generates test cases suitable to the LC and assess how the
model behaves on a specific linguistic characteristics in input
sentences. This method is different from the adversarial methods in a
sense that the adversarial approaches rely on generating error-causing
test cases, and they are limited to assess NLP models on multiple
linguistic characteristics.

>Motivation of using linguistic capabilities

Traditional train-valid-test split tests NLP models aggregately and
the test set reveals biases and fail to comprehensive testing the
models. Therefore, prior work (e.g. CHECKLIST) introduced multiple
task relevant LCs and relevant test cases. It enables assess NLP
models over the multiple LCs. However, it requires manual effort to
generate relevant test cases, and it results in obtaining limited
semantic and syntactic attributes. In addition, It requires
non-trivial manual efforts to define the metamorphic relations between
inputs and outputs because semantics of nature language can be greatly
changed even by a slight perturbation to the sentences. In this work,
we automates LC-relevant test cases generation using the same LCs
provided in CEHCKLIST.

__REVIEW_2&3

>Limited Applicability & Generalizability

We show the applicability and generalizability of the S^2LCT by
implementing it for other NLP task. In this work, we implement the
S^2LCT for hate speech detection task. For its experiment, we use
first 14 functionalities for the task introduced from the hatecheck
(https://arxiv.org/abs/2012.15606), and we use all seeds for its
expansion. Models under test for this experiment are
Hate-speech-CNERG/bert-base-uncased-hatexplain-rationale-two,
DaNLP/da-electra-hatespeech-detection and
DaNLP/da-bert-hatespeech-detection. The experiment result over the
functionalities are added in the attachment. We will also add the
results in our final version.

__REVIEW_1

>How much effort involved in specifying the rules?

LCs in CHECKLIST are described in a sentence, thus it is not clear to
specify linguistic characteristics of interest and how the input and
output should be formed because of semantic and structure diversity in
natural language. Thus, we manually specify rule for seed generation
for each LCs in CHECKLIST to achieve the semantic and structure
diversity. In practice, we spent less than 10 min to generate each LC.

__REVIEW_2

>No discussion or results about repair strategy.

In the section VI of our paper, we show the effectiveness of S^2LCT
for finding root causes of bugs.

__REVIEW_3

>Significant effort in defining search rules and transformation

I agree that S^2LCT requires manual specification of search rules and
transformation.

>Fail Rate for CHECKLIST

We add the fail rates for CHECKLIST in the attachment.
We will also add the results in our final version.

>Label Consistency

During the manual study to measure label consistency, it is observed
that the 83% of label consistency of the seed sentences comes from
inconsistency between label and the raw sentences in the dataset, and
it results in the 84% of label consistency of expanded
sentences. Accordingly, we also empirically compare seed sentences and
their expanded sentences from the pass-to-fail cases in the table II
to check the label consistency of the expanded sentences. From the
comparison, it is observed that no expanded words change the sentiment
of the expanded sentences and the expanded words preserves the label
consistency.
