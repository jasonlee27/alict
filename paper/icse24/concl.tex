\section{Conclusions}
\label{sec:concl}

We introduce \tool, which automatically generates test cases for testing NLP models. We evaluate the effectiveness of \tool on two popular NLP tasks.
Our study results reveal that the diversity of \tool's test cases improves model coverage and reliability. Additionally, we analyze failure-inducing cases to identify bug causes, demonstrating the correctness and utility of \tool for model evaluation.